---
title: "Generative autoregressive networks for 3d dancing move synthesis from music"
collection: publications
category: manuscripts
permalink: /publication/paper1
excerpt: 'Hyemin Ahn, Jaehun Kim, Kihyun Kim, Songhwai Oh'
date: 2020-01-01
venue: 'IEEE Robotics and Automation Letters'
slidesurl: 
paperurl: 'https://arxiv.org/pdf/1911.04069'
citation: 
---

This paper proposes a framework which is able to generate a sequence of three-dimensional human dance poses for a given music. The proposed framework consists of three components: a music feature encoder, a pose generator, and a music genre classifier. We focus on integrating these components for generating a realistic 3D human dancing move from music, which can be applied to artificial agents and humanoid robots. The trained dance pose generator, which is a generative autoregressive model, is able to synthesize a dance sequence longer than 5,000 pose frames. Experimental results of generated dance sequences from various songs show how the proposed method generates human-like dancing move to a given music. In addition, a generated 3D dance sequence is applied to a humanoid robot, showing that the proposed framework can make a robot to dance just by listening to music.